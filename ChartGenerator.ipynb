{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67a05456",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Libraries\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50248aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "##BBC Chart\n",
    "bbc = requests.get('https://www.bbc.co.uk/programmes/articles/3tqPdBWF9yMbTrfjWvfKV8t/radio-1-playlist')\n",
    "soup = BeautifulSoup(bbc.text, 'html.parser')\n",
    "\n",
    "chart = soup.select('.text--prose')\n",
    "\n",
    "aList_soup = chart[1].find_all('p', string=True)\n",
    "bList_soup = chart[2].find_all('p', string=True)\n",
    "cList_soup = chart[3].find_all('p', string=True)\n",
    "\n",
    "def cleanData(ls, name):\n",
    "    df = []\n",
    "    rank = 1\n",
    "    name = name\n",
    "    for i in ls:\n",
    "        trim = i.get_text()\n",
    "        if trim[0] == 'â†‘':\n",
    "            trim = trim[2:]\n",
    "        tup = (trim.split('-')[0].lower(), trim.split('-')[1].lower(), rank, name)\n",
    "        df.append(tup)\n",
    "        rank += 1\n",
    "    return df\n",
    "\n",
    "aList = cleanData(aList_soup, 'A-List')\n",
    "bList = cleanData(bList_soup, 'B-List')\n",
    "cList = cleanData(cList_soup, 'C-List')\n",
    "\n",
    "bbc_chart = aList + bList + cList\n",
    "\n",
    "df1 = pd.DataFrame(bbc_chart, columns=['Artist', 'Song', 'Rank', 'Chart-Name'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92b98355",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Official Charts Data\n",
    "offChart = requests.get('https://www.officialcharts.com/charts/')\n",
    "\n",
    "chartSoup = BeautifulSoup(offChart.text, 'html.parser')\n",
    "\n",
    "offChartText = chartSoup.select('.chart-positions')\n",
    "headings =  []\n",
    "for i in offChartText[0].find_all('th'):\n",
    "    headings.append(i.get_text())\n",
    "    \n",
    "rows = offChartText[0].find_all('tr')\n",
    "\n",
    "rowsArr = []\n",
    "for i in rows:\n",
    "    cleanRow = i.get_text().replace('\\n',' ').replace('\\r',' ').replace('   ', ',').replace('  ', ',')\n",
    "    rowsArr.append(cleanRow)\n",
    "\n",
    "rowsArr = [i for i in rowsArr if i != ' Pos LW Title, Artist PeakPos WoC,ChartFacts ']\n",
    "rowsArr = [i for i in rowsArr if i != ',Buy Listen,']\n",
    "rowsArr = [i for i in rowsArr if i != ',amazon itunes, ']\n",
    "rowsArr = [i for i in rowsArr if i != ',,']\n",
    "rowsArr = [i for i in rowsArr if i != ',deezer spotify, ']\n",
    "rowsArr = [i for i in rowsArr if i != ',spotify deezer, ']\n",
    "rowsArr = [i for i in rowsArr if i != ',Buy,']\n",
    "rowsArr = [i for i in rowsArr if i != ',amazon, ']\n",
    "rowsArr = [i for i in rowsArr if i != ',itunes, ']\n",
    "rowsArr = [i for i in rowsArr if i != ',spotify, ']\n",
    "rowsArr = [i for i in rowsArr if i != ',deezer, ']\n",
    "\n",
    "# Prepare data for DF\n",
    "officialData = []\n",
    "\n",
    "for i in rowsArr:\n",
    "    row = i.split(',')\n",
    "    cleanRow = list(filter(None, row))\n",
    "    if len(cleanRow) > 4:\n",
    "        tup = (cleanRow[3].lower(), cleanRow[2].lower(), cleanRow[0], 'Official Charts')\n",
    "        officialData.append(tup)\n",
    "\n",
    "# Create DF\n",
    "df2 = pd.DataFrame(officialData, columns=['Artist', 'Song', 'Rank', 'Chart-Name'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b73943dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Big top 40\n",
    "\n",
    "\n",
    "big40Chart = requests.get('https://www.bigtop40.com/')\n",
    "big40ChartSoup = BeautifulSoup(big40Chart.text, 'html.parser')\n",
    "big40ChartText = big40ChartSoup.select('.chart-module__charts')\n",
    "\n",
    "rows = big40ChartText[0].find_all('li')\n",
    "big40ChartData = []\n",
    "for i in rows:\n",
    "    cleanRow = i.get_text().replace('\\n','').replace('\\t','').replace('                                                            ', ',').replace('                                                    ', ',').split(',')\n",
    "    big40ChartData.append((cleanRow[3].lower(), cleanRow[1].lower(), cleanRow[0], 'Big top 40'))\n",
    "                     \n",
    "            \n",
    "# Create DF\n",
    "df3 = pd.DataFrame(big40ChartData, columns=['Artist', 'Song', 'Rank', 'Chart-Name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d1da66e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "allData = pd.concat([df1, df2, df3], ignore_index=True)\n",
    "# allData.to_csv('./out.csv')\n",
    "\n",
    "chars_count = allData['Chart-Name'].value_counts()\n",
    "allData.reset_index()\n",
    "\n",
    "points = []\n",
    "for index, row in allData.iterrows():\n",
    "    if row['Chart-Name'] == 'Official Charts':\n",
    "            points.append(int(chars_count['Official Charts']) + 1 - int(row['Rank']))\n",
    "    elif row['Chart-Name'] == 'A-List':\n",
    "            points.append(101 + int(chars_count['A-List']) - (int(chars_count['A-List']) + int(row['Rank'])))\n",
    "    elif row['Chart-Name'] == 'B-List':\n",
    "            points.append(101 + int(chars_count['B-List']) - (int(chars_count['B-List']) + int(row['Rank'])))\n",
    "    elif row['Chart-Name'] == 'C-List':\n",
    "            points.append(101 + int(chars_count['C-List']) - (int(chars_count['C-List']) + int(row['Rank'])))\n",
    "    elif row['Chart-Name'] == 'Big top 40':\n",
    "            points.append(101 + int(chars_count['Big top 40']) - (int(chars_count['Big top 40']) +int(row['Rank'])))\n",
    "            \n",
    "\n",
    "allData['points'] = points\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4a42ab2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "unique_songs = allData['Song'].value_counts()\n",
    "\n",
    "total_points = []\n",
    "artist_list = []\n",
    "songs_list = []\n",
    "\n",
    "for index, value in unique_songs.items():\n",
    "    tot = allData.loc[allData['Song'] == index, 'points'].sum()\n",
    "    total_points.append(tot)\n",
    "    artist = allData.iloc[allData[allData['Song'] == index].first_valid_index()]['Artist']\n",
    "    artist_list.append(artist)\n",
    "    songs_list.append(index)\n",
    "\n",
    "lst = zip(artist_list, songs_list, total_points)\n",
    "\n",
    "final_chart = pd.DataFrame(lst, columns=['Artist', 'Song', 'Combined Points'])\n",
    "final_chart.sort_values(by=['Combined Points'])\n",
    "final_chart_sorted = final_chart.sort_values(by=['Combined Points'], ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15a9013b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-04-28_Chart_Combined.xlsx\n"
     ]
    }
   ],
   "source": [
    "from datetime import date\n",
    "\n",
    "today = date.today()\n",
    "file_name = str(today) + '_Chart_Combined.xlsx'\n",
    "\n",
    "print(file_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e655f412",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final_chart_sorted.reset_index().to_excel(file_name) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dff4ece",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
